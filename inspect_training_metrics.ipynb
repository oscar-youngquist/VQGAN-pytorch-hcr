{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import utils as vutils\n",
    "from discriminator import Discriminator\n",
    "from lpips import LPIPS\n",
    "from vqgan import VQGAN\n",
    "from utils import load_data, weights_init\n",
    "import lightning as L\n",
    "from vqgan_lightning import LitVQGAN\n",
    "import json\n",
    "from utils import ImagePaths\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pull out the current working directory\n",
    "# cwd = os.getcwd()\n",
    "\n",
    "# # appened the directory with actual images\n",
    "# new_path_prefix = os.path.join(cwd, \"..\", \"processed_data\", \"reprocessed_resizedimages_revised.json\")\n",
    "# print(new_path_prefix)\n",
    "\n",
    "# # open the json and fix it first\n",
    "# json_df = pd.read_json(new_path_prefix)\n",
    "\n",
    "# # extract negative file-paths\n",
    "# negative_image_paths = json_df[json_df[\"time_step_label\"] == 1].image_file_path.to_list()\n",
    "\n",
    "# new_file_path = os.path.join(cwd, \"..\", \"processed_data\", \"negative_image_paths.txt\")\n",
    "# # write out negative data\n",
    "# with open(new_file_path, \"w+\") as f:\n",
    "#     for line in negative_image_paths:\n",
    "#         f.write(f\"{line}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "model_folder_path = os.path.join(cwd, \"training_results\", \"04_03_202412_45_58\")\n",
    "model_file_path = os.path.join(model_folder_path, \"lightning_logs\", \"version_0\", \"checkpoints\", \"epoch=17-step=4019112.ckpt\")\n",
    "\n",
    "\n",
    "\n",
    "negative_data_path = os.path.join(cwd, \"..\", \"processed_data\", \"negative_image_paths.txt\")\n",
    "\n",
    "eval_output_path = os.path.join(model_folder_path, \"negative_images\")\n",
    "\n",
    "if not os.path.exists(eval_output_path):\n",
    "    os.makedirs(eval_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load negative image data\n",
    "test_data = ImagePaths(negative_data_path, size=256)\n",
    "negative_data_loader = DataLoader(test_data, batch_size=1, shuffle=False, num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load trained model\n",
    "vqgan = LitVQGAN.load_from_checkpoint(model_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vqgan.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_num = 0\n",
    "for im in negative_data_loader:\n",
    "    recon, diff = vqgan.encode_GAT_nodes(im.cuda())\n",
    "    # diff = torch.abs(recons - im)\n",
    "\n",
    "    im_np = torch.squeeze(im).permute(1,2,0).cpu().tolist()\n",
    "    recons_np = torch.squeeze(recon).permute(1,2,0).cpu().tolist()\n",
    "    diff_np = torch.squeeze(diff).permute(1,2,0).cpu().tolist()\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, squeeze=True)\n",
    "    \n",
    "    axes[0].imshow(im_np)\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title(\"Input\")\n",
    "    axes[1].imshow(recons_np)\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title(\"Recon.\")\n",
    "    axes[2].imshow(diff_np)\n",
    "    axes[2].axis('off')\n",
    "    axes[2].set_title(\"Diff.\")\n",
    "    new_path = os.path.join(eval_output_path, \"neg_eval_sample_{:d}.png\".format(batch_num))\n",
    "    batch_num += 1\n",
    "    fig.savefig(new_path)\n",
    "    plt.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "taming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
